{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Outbrain: ETL with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will do preprocessing and feature engineering using [Kaggle Outbrain dataset](https://www.kaggle.com/c/outbrain-click-prediction).\n",
    "\n",
    "**Learning objectives**\n",
    "\n",
    "In this notebook, we learn how to \n",
    "\n",
    "- Use LambdaOp for custom row-wise dataframe manipulations with NVTabular\n",
    "- Preprocess single-hot categorical input features with NVTabular\n",
    "- Apply TargetEncoding to categorical features\n",
    "- Create a custom operator to create time features\n",
    "- Apply ColumnSimilarity to calculate the similarity between two columns using tf-idf metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import graphviz\n",
    "import gc\n",
    "\n",
    "import cupy\n",
    "import cudf\n",
    "import rmm\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.ops import Normalize, FillMedian, FillMissing, Categorify, LogOp, LambdaOp, JoinGroupby, TargetEncoding, get_embedding_sizes, Rename\n",
    "from nvtabular.ops.column_similarity import ColumnSimilarity\n",
    "\n",
    "from nvtabular import ColumnGroup, Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set where the dataset should be saved once processed (OUTPUT_BUCKET_FOLDER), as well as where the dataset originally resides (DATA_BUCKET_FOLDER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BUCKET_FOLDER = os.environ.get(\"INPUT_DATA_DIR\", \"/outbrain/\")\n",
    "OUTPUT_BUCKET_FOLDER = os.environ.get(\"OUTPUT_DATA_DIR\", \"/outbrain/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/outbrain/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_BUCKET_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read our saved train and valid datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = os.path.join(OUTPUT_BUCKET_FOLDER, \"train_gdf.parquet\")\n",
    "valid_filename = os.path.join(OUTPUT_BUCKET_FOLDER, \"valid_gdf.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/outbrain/train_gdf.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_train = cudf.read_parquet(train_filename, num_rows =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "display_id              int64\n",
       "ad_id                   int64\n",
       "clicked                 int64\n",
       "uuid                   object\n",
       "document_id             int64\n",
       "timestamp               int64\n",
       "platform              float64\n",
       "geo_location           object\n",
       "document_id_promo       int64\n",
       "campaign_id             int64\n",
       "advertiser_id           int64\n",
       "source_id             float64\n",
       "publisher_id          float64\n",
       "publish_time           object\n",
       "source_id_promo       float64\n",
       "publisher_id_promo    float64\n",
       "publish_time_promo     object\n",
       "day_event               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_train.publish_time.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudf.utils.dtypes \n",
    "cudf.utils.dtypes.is_string_dtype(gdf_train.publish_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing documents metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the output directories to store the preprocessed parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "output_train_dir = os.path.join(OUTPUT_BUCKET_FOLDER, 'train/')\n",
    "output_valid_dir = os.path.join(OUTPUT_BUCKET_FOLDER, 'valid/')\n",
    "! mkdir -p $output_train_dir\n",
    "! mkdir -p $output_valid_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in three more cudf data frames, <i>documents categories</i>, <i>topics</i>, and <i>entities</i>, and use them to create sparse matrices in cupy. We will use these later to calculate cosine similarity between event document (landing page context) and ad document profile vectors (TF-IDF), i.e., how close in profile an ad is to the page that it is being displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_categories_cudf = cudf.read_csv(DATA_BUCKET_FOLDER + 'documents_categories.csv')\n",
    "documents_topics_cudf = cudf.read_csv(DATA_BUCKET_FOLDER + 'documents_topics.csv')\n",
    "documents_entities_cudf = cudf.read_csv(DATA_BUCKET_FOLDER + 'documents_entities.csv')\n",
    "# read in document categories/topics/entities as cupy sparse matrices\n",
    "def df_to_coo(df, row=\"document_id\", col=None, data=\"confidence_level\"):\n",
    "    return cupy.sparse.coo_matrix((df[data].values, (df[row].values, df[col].values)))\n",
    "\n",
    "categories = df_to_coo(documents_categories_cudf, col=\"category_id\")\n",
    "topics = df_to_coo(documents_topics_cudf, col=\"topic_id\")\n",
    "documents_entities_cudf['entity_id'] = documents_entities_cudf['entity_id'].astype(\"category\").cat.codes\n",
    "entities = df_to_coo(documents_entities_cudf, col=\"entity_id\")\n",
    "\n",
    "documents_categories_cudf = documents_topics_cudf = documents_entities_cudf =  None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate NVTabular Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our datasets, sparse matrices and udf are created, we can begin laying the groundwork for NVTabular. NVTabular requires input features to be defined as groups of columns , so we define our ColumnGroup features at this step. Note that feature engineering and preprocessing often happens to sets of columns, so we adopt that method and require the user to specify continuous and categoricals along with the target as lists within ColumnGroup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our data still isn’t in a form that’s ideal for consumption by our W&D model that we will train in the next notebook. There are missing values, and our categorical variables are still represented by random, discrete identifiers, and need to be transformed into contiguous indices for embedding lookups. The distributions of our continuous variables are uncentered. We also would like to create new features that will help to increase the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin to create and process features using NVTabular ops:\n",
    " * <i>geo_location_state</i> and <i>geo_location_country</i> are created by stripping geo_location using the `LambdaOp`\n",
    " * <i>publish_time_days_since_published</i> and <i>publish_time_promo_days_since_published</i> features are created using the `calculate_delta` function in a `LambdaOp`\n",
    " * Missing values are filled using median value depending on the feature using `FillMedian()`op\n",
    " * Continuous features are log transformed with the `LogOp()`.\n",
    " \n",
    "`Categorify` op is used for categorification, i.e. encoding of categorical features. Categorify op takes a param called `freq_threshold` which is used for frequency capping. This handy functionality will map all categories which occur in the dataset with some threshold level of infrequency to the _same_ index, keeping the model from overfitting to sparse signals. We don't apply  frequency thresholds in this example, but one can easily create a frequency threshold dictionary, assign a custom threshold value for each categorical feature, and feed that dictionary into the `Categorify` op as `freq_threshold` param."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the important part of building recommender systems is to do feature engineering. As a very promising feature engineering technique, `Target Encoding` processes the categorical features and makes them easier accessible to the model during training and validation. *Target Encoding (TE)* has emerged as being both effective and efficient in many data science projects. For example, it is the major component of Nvidia Kaggle Grandmasters team’s [winning solution](https://medium.com/rapids-ai/winning-solution-of-recsys2020-challenge-gpu-accelerated-feature-engineering-and-training-for-cd67c5a87b1f) of [Recsys Challenge 2020](http://www.recsyschallenge.com/2020/). TE calculates the statistics from a target variable grouped by the unique values of one or more categorical features. For example in a binary classification problem, it calculates the probability that the target is true for each category value - a simple mean. In other words, for each distinct element in feature <b>$x$</b> we are going to compute the average of the corresponding values in target <i>y</i>. Then we are going to replace each $x_{i}$ with the corresponding mean value. For more details on TargetEncoding please visit [here](https://medium.com/rapids-ai/target-encoding-with-rapids-cuml-do-more-with-your-categorical-data-8c762c79e784) and [here](https://github.com/rapidsai/deeplearning/blob/main/RecSys2020Tutorial/03_3_TargetEncoding.ipynb).\n",
    "\n",
    "Here, we apply Target Encoding to certain categorical features with *kfold* of 5 and *smoothing* of 20 to avoid overfitting using [TargetEncoding op](https://github.com/NVIDIA/NVTabular/blob/a0141d0a710698470160bc2cbc42b18ce2d49133/nvtabular/ops/target_encoding.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a custom operator that calculates the time difference between a specified time column (either publish_time or publish_time_promo) and timestamp. This is used to calculate <i>time elapsed since publication</i> between the landing page and the ad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save disk space, the timestamps in the entire dataset are relative to the first time in the dataset. \n",
    "#To recover the actual epoch time of the visit, we add 1465876799998 to the timestamp.\n",
    "TIMESTAMP_DELTA = 1465876799998\n",
    "\n",
    "from nvtabular.ops import Operator\n",
    "\n",
    "class DaysSincePublished(Operator):\n",
    "    def transform(self, columns, gdf):\n",
    "        for column in columns:\n",
    "            col = gdf[column]\n",
    "            col.loc[col == \"\"] = None\n",
    "            col.loc[col == \"None\"] = None\n",
    "            col = col.astype('datetime64[ms]')\n",
    "            timestamp = (gdf['timestamp']+TIMESTAMP_DELTA).astype('datetime64[ms]')\n",
    "            delta = (timestamp - col).dt.days\n",
    "            gdf[column + \"_since_published\"] = delta * (delta >=0) * (delta<=10*365)\n",
    "        return gdf\n",
    "            \n",
    "    def output_column_names(self, columns):\n",
    "        return [column + \"_since_published\" for column in columns]\n",
    "            \n",
    "    def dependencies(self):\n",
    "        return [\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo processing: apply two different lambda operators to the ‘geo_location’ column, and \n",
    "# extract the country/state from the geo_location value. The geo_location column\n",
    "# looks something like \"US>CA>12345\", so we're using string slicing to pull out the country\n",
    "# and the country+state then \n",
    "geo_location = ColumnGroup([\"geo_location\"])\n",
    "country = geo_location >> (lambda col: col.str.slice(0, 2)) >> Rename(postfix=\"_country\")\n",
    "state = geo_location >> (lambda col: col.str.slice(0, 5)) >> Rename(postfix=\"_state\")\n",
    "geo_features = geo_location + country + state\n",
    "\n",
    "# categoricals processing: categorify certain input columns as well as the geo features\n",
    "cats = ColumnGroup(['ad_id', 'document_id', 'platform', 'document_id_promo', 'campaign_id', 'advertiser_id', 'source_id', 'publisher_id', 'source_id_promo', 'publisher_id_promo'])\n",
    "cat_features = geo_features + cats >> Categorify()\n",
    "\n",
    "# Apply TargetEncoding to certain categoricals with kfold of 1 and smoothing of 20\n",
    "te_features = cats >> TargetEncoding(\"clicked\", kfold=5, p_smooth=20)\n",
    " \n",
    "# process dates using the ‘DaysSincePublished’ custom operator\n",
    "dates = [\"publish_time\", \"publish_time_promo\"]\n",
    "date_features = dates >> DaysSincePublished() >> FillMedian() >> LogOp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our calculation graph with the column groups we used and created so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1689pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 1688.93 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 1684.93,-472 1684.93,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"437.69\" cy=\"-234\" rx=\"84.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.69\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">TargetEncoding</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"815.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"815.69\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;11 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>0&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M477.43,-218.07C552.59,-189.84 714.2,-129.13 783.29,-103.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"784.66,-106.4 792.79,-99.6 782.2,-99.84 784.66,-106.4\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"437.69\" cy=\"-306\" rx=\"214.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.69\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[ad_id, document_id, platform...]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.69,-287.7C437.69,-279.98 437.69,-270.71 437.69,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"441.19,-262.1 437.69,-252.1 434.19,-262.1 441.19,-262.1\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"756.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"756.69\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.48,-289.03C576.54,-274.53 671.11,-253.78 721.66,-242.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"722.44,-246.1 731.46,-240.54 720.94,-239.26 722.44,-246.1\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"102.69\" cy=\"-306\" rx=\"102.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.69\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[clicked]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>6&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.1,-291.75C224.19,-279.61 309.97,-261.69 369.52,-249.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"370.51,-252.61 379.59,-247.14 369.08,-245.76 370.51,-252.61\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"718.69\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"718.69\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M727.89,-288.05C732.44,-279.68 738.01,-269.4 743.05,-260.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"746.14,-261.77 747.84,-251.31 739.99,-258.43 746.14,-261.77\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"705.69\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"705.69\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>10&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M708.9,-359.7C710.34,-351.98 712.06,-342.71 713.66,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"717.13,-334.58 715.51,-324.1 710.25,-333.3 717.13,-334.58\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"756.69\" cy=\"-162\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"756.69\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M756.69,-215.7C756.69,-207.98 756.69,-198.71 756.69,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"760.19,-190.1 756.69,-180.1 753.19,-190.1 760.19,-190.1\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"794.69\" cy=\"-450\" rx=\"128.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"794.69\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[geo_location]</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;10 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>15&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M773.15,-432.05C761.41,-422.83 746.75,-411.29 734.1,-401.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"736.14,-398.5 726.12,-395.07 731.82,-404 736.14,-398.5\"/>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>15&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M793.94,-431.86C792.37,-402.19 787.8,-339.51 775.69,-288 773.57,-278.97 770.41,-269.36 767.27,-260.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"770.51,-259.5 763.67,-251.42 763.98,-262.01 770.51,-259.5\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"883.69\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.69\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;4 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>15&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M816.24,-432.05C827.97,-422.83 842.63,-411.29 855.29,-401.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"857.57,-404 863.26,-395.07 853.24,-398.5 857.57,-404\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"877.69\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"877.69\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>13&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M852.62,-290.5C833.05,-279.17 805.85,-263.44 785.4,-251.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"786.95,-248.46 776.54,-246.48 783.44,-254.52 786.95,-248.46\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;13 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>4&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M882.21,-359.7C881.55,-351.98 880.75,-342.71 880.01,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"883.5,-333.77 879.16,-324.1 876.52,-334.37 883.5,-333.77\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1192.69\" cy=\"-378\" rx=\"229.36\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1192.69\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[publish_time, publish_time_promo]</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1192.69\" cy=\"-306\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1192.69\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">DaysSincePublished</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1192.69,-359.7C1192.69,-351.98 1192.69,-342.71 1192.69,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1196.19,-334.1 1192.69,-324.1 1189.19,-334.1 1196.19,-334.1\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1052.69\" cy=\"-234\" rx=\"60.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1052.69\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMedian</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"875.69\" cy=\"-162\" rx=\"40.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"875.69\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">LogOp</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;12 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>7&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1017.72,-219.17C987.99,-207.41 945.36,-190.55 914.57,-178.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"915.6,-175.02 905.02,-174.6 913.03,-181.53 915.6,-175.02\"/>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1160.22,-288.76C1139.81,-278.56 1113.37,-265.34 1091.81,-254.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1093.11,-251.29 1082.6,-249.95 1089.97,-257.56 1093.11,-251.29\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;11 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>8&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M770.67,-144.41C778.34,-135.31 787.96,-123.9 796.34,-113.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"799.25,-115.94 803.02,-106.04 793.89,-111.43 799.25,-115.94\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1560.69\" cy=\"-378\" rx=\"120.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1560.69\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[timestamp]</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;9 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>14&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1489.3,-363.42C1426.41,-351.46 1334.99,-334.07 1270.3,-321.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1270.64,-318.26 1260.16,-319.83 1269.33,-325.14 1270.64,-318.26\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"815.69\" cy=\"-18\" rx=\"464.12\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"815.69\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols=[publish_time_since_published, publish_time_promo_since_published, geo_location...]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;17 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>11&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M815.69,-71.7C815.69,-63.98 815.69,-54.71 815.69,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"819.19,-46.1 815.69,-36.1 812.19,-46.1 819.19,-46.1\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;11 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M861.77,-144.76C853.91,-135.59 843.95,-123.96 835.3,-113.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"837.88,-111.5 828.71,-106.19 832.56,-116.06 837.88,-111.5\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1037.69\" cy=\"-162\" rx=\"102.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1037.69\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[clicked]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;11 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M990.07,-145.98C947.79,-132.65 887.08,-113.51 849.58,-101.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"850.24,-98.22 839.65,-98.55 848.13,-104.9 850.24,-98.22\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f3759270b50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = date_features + cat_features + te_features + \"clicked\"\n",
    "features.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user might sometimes be interested to continue reading about the same topics of the current page. Computing the similarity between the textual content of the current page and the pages linked to the displayed ads, can be a relevant feature for a model that predicts which ad the user would click next. A simple, yet effective way to compute the similarity between documents is generating the TF-IDF vectors for each of them, which captures their most relevant terms, and then computing the cosine similarity between those vectors.\n",
    " \n",
    "Below, we calculate <i>doc_event_doc_ad_sim_categories</i>, <i>topics</i>, and <i>entities</i> using the `ColumnSimilarity` op, which utilizes the sparse categories, topics, and entities matrices that were created above to calculate landing page similarity for categories, topics, and entities. We calculate Cosine similarity between event doc (landing page) and ad doc aspects vectors (TF-IDF). Creating these extra features help to improve model accuracy and predictability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we rename the column names to avoid duplicated column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvtabular/nvtabular/ops/column_similarity.py:229: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(N / np.bincount(X.col))\n"
     ]
    }
   ],
   "source": [
    "sim_features_categ = [[\"document_id\", \"document_id_promo\"]] >> ColumnSimilarity(categories, metric='tfidf', on_device=False) >> Rename(postfix=\"_categories\")\n",
    "sim_features_topics= [[\"document_id\", \"document_id_promo\"]] >> ColumnSimilarity(topics, metric='tfidf', on_device=False) >> Rename(postfix=\"_topics\")\n",
    "sim_features_entities= [[\"document_id\", \"document_id_promo\"]] >> ColumnSimilarity(entities, metric='tfidf', on_device=False) >> Rename(postfix=\"_entities\")\n",
    "sim_features = sim_features_categ + sim_features_topics +  sim_features_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The workflow is created with the output node of the graph\n",
    "workflow = nvt.Workflow(features + sim_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create an NVTabular Dataset object both for train and validation sets. We calculate statistics for this workflow on the input dataset, i.e. on our training set, using the `workflow.fit()` method so that our <i>Workflow</i> can use these stats to transform any given input. When our <i>Workflow</i> transorms our datasets and, we also save the results out to parquet files for fast reading at train time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = nvt.Dataset(train_filename)\n",
    "valid_dataset = nvt.Dataset(valid_filename)\n",
    "\n",
    "# Calculate statistics on the training set\n",
    "workflow.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the calculated statistics to transform the train/valid datasets \n",
    "# and write out each as parquet\n",
    "workflow.transform(train_dataset).to_parquet(output_path=output_train_dir, shuffle=Shuffle.PER_PARTITION, out_files_per_proc=5)\n",
    "workflow.transform(valid_dataset).to_parquet(output_path=output_valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the stats from the workflow and load it anytime, so we can run training without doing preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebooks, we will train a deep learning model. Our training pipeline requires information about the data schema to define the neural network architecture. We will save the NVTabular workflow to disk so that we can restore it in the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(OUTPUT_BUCKET_FOLDER, 'workflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"outbrain_nvt\"\n",
       "input {\n",
       "  name: \"publisher_id\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"source_id\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"source_id_promo\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"geo_location\"\n",
       "  data_type: TYPE_STRING\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"advertiser_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"document_id_promo\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"document_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"publisher_id_promo\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"clicked\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"publish_time_promo\"\n",
       "  data_type: TYPE_STRING\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"platform\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"campaign_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"ad_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"timestamp\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "input {\n",
       "  name: \"publish_time\"\n",
       "  data_type: TYPE_STRING\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"publish_time_since_published\"\n",
       "  data_type: TYPE_FP32\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"publish_time_promo_since_published\"\n",
       "  data_type: TYPE_FP32\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"geo_location\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"geo_location_country\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"geo_location_state\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"ad_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"document_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"platform\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"document_id_promo\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"campaign_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"advertiser_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"source_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"publisher_id\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"source_id_promo\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"publisher_id_promo\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_ad_id_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_document_id_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_platform_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_document_id_promo_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_campaign_id_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_advertiser_id_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_source_id_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_publisher_id_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_source_id_promo_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"TE_publisher_id_promo_clicked\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"clicked\"\n",
       "  data_type: TYPE_INT64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"document_id_document_id_promo_sim_categories\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"document_id_document_id_promo_sim_topics\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "output {\n",
       "  name: \"document_id_document_id_promo_sim_entities\"\n",
       "  data_type: TYPE_FP64\n",
       "  dims: -1\n",
       "  dims: 1\n",
       "}\n",
       "backend: \"python\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nvtabular.inference.triton import generate_nvtabular_model\n",
    "generate_nvtabular_model(workflow, \"outbrain_nvt\", \"/outbrain/tf_models/outbrain_nvt/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow = Workflow.load(os.path.join(OUTPUT_BUCKET_FOLDER, 'workflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.input_dtypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(workflow.input_dtypes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_dataset = nvt.Dataset(valid_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write to new \"shuffled\" and \"processed\" dataset\n",
    "# workflow.transform(valid_dataset).to_parquet(output_path='./valid/', out_files_per_proc=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_PATHS = sorted(glob.glob(os.path.join(OUTPUT_BUCKET_FOLDER, 'train/*.parquet')))\n",
    "# VALID_PATHS = sorted(glob.glob(os.path.join(OUTPUT_BUCKET_FOLDER, 'valid/*.parquet')))\n",
    "# TRAIN_PATHS, VALID_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = cudf.read_parquet(TRAIN_PATHS[0])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEND REQUEST TO TRITON FOR NVT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies\n",
    "import os\n",
    "\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.grpc as grpcclient\n",
    "import nvtabular\n",
    "import cudf\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "HTTP/1.1 200 OK\n",
      "\u001b[1mContent-Length\u001b[0m: 0\n",
      "\u001b[1mContent-Type\u001b[0m: text/plain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!curl -i 10.110.20.127:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>platform</th>\n",
       "      <th>source_id_promo</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>publisher_id_promo</th>\n",
       "      <th>document_id</th>\n",
       "      <th>publish_time_promo</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>clicked</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>document_id_promo</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183855</td>\n",
       "      <td>4141173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7941.0</td>\n",
       "      <td>US&gt;TX&gt;600</td>\n",
       "      <td>1685</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1788099</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-13 21:00:00</td>\n",
       "      <td>850713</td>\n",
       "      <td>22122</td>\n",
       "      <td>10345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187797</td>\n",
       "      <td>5272727</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8254.0</td>\n",
       "      <td>US&gt;CA&gt;807</td>\n",
       "      <td>769</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1794963</td>\n",
       "      <td>2015-09-28 00:00:00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-14 00:00:00</td>\n",
       "      <td>1116986</td>\n",
       "      <td>15431</td>\n",
       "      <td>1675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244543</td>\n",
       "      <td>645068</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8230.0</td>\n",
       "      <td>US&gt;MN&gt;702</td>\n",
       "      <td>2146</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1783066</td>\n",
       "      <td>2016-02-18 06:00:00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-13 19:00:00</td>\n",
       "      <td>1100702</td>\n",
       "      <td>25978</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ad_id  timestamp  platform  source_id_promo geo_location  advertiser_id  \\\n",
       "0  183855    4141173       2.0           7941.0    US>TX>600           1685   \n",
       "1  187797    5272727       2.0           8254.0    US>CA>807            769   \n",
       "2  244543     645068       3.0           8230.0    US>MN>702           2146   \n",
       "\n",
       "  publisher_id_promo  document_id   publish_time_promo  publisher_id  clicked  \\\n",
       "0               <NA>      1788099                 <NA>         440.0        0   \n",
       "1               <NA>      1794963  2015-09-28 00:00:00         236.0        0   \n",
       "2               <NA>      1783066  2016-02-18 06:00:00         206.0        0   \n",
       "\n",
       "          publish_time  document_id_promo  campaign_id  source_id  \n",
       "0  2016-06-13 21:00:00             850713        22122    10345.0  \n",
       "1  2016-06-14 00:00:00            1116986        15431     1675.0  \n",
       "2  2016-06-13 19:00:00            1100702        25978      105.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the workflow (to get input/output schema to call triton with)\n",
    "\n",
    "workflow = nvtabular.Workflow.load(\"/outbrain/tf_models/outbrain_nvt/1/workflow\")\n",
    "\n",
    "# read in a batch of data to get transforms for\n",
    "batch = cudf.read_parquet(valid_filename, num_rows=3)[list(workflow.input_dtypes.keys())]\n",
    "\n",
    "# print(batch, \"\\n\")\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the batch to a triton inputs\n",
    "columns = [(col, batch[col][0:3]) for col in list(workflow.input_dtypes.keys())]\n",
    "# print(columns.dtype)\n",
    "\n",
    "inputs = []\n",
    "\n",
    "# col_dtypes = [np.int64, np.int64]\n",
    "\n",
    "# col_dtypes = [np.float64, np.float64, np.int64, np.int64, np.float64, np.float64, np.int64, np.int64,  np.float64, np.int64, np.int64,\n",
    "#               np.object, np.object, np.int64, np.object] \n",
    "\n",
    "for i, (name, col) in enumerate(columns):\n",
    "    d = col.values_host.astype(col.dtype)\n",
    "    d = d.reshape(len(d),1)\n",
    "    inputs.append(grpcclient.InferInput(name, d.shape, np_to_triton_dtype(col.dtype)))\n",
    "    inputs[i].set_data_from_numpy(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder variables for the output\n",
    "outputs = [grpcclient.InferRequestedOutput(name) for name in workflow.column_group.columns]\n",
    "# make the request\n",
    "# replace <localhost> with your host ip address.\n",
    "with grpcclient.InferenceServerClient(\"10.110.20.127:8001\") as client:\n",
    "    response = client.infer(\"outbrain_nvt\", inputs, request_id=\"1\",outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publish_time_since_published  publish_time_promo_since_published  \\\n",
      "0                           0.0                            4.564348   \n",
      "1                           0.0                            5.564520   \n",
      "2                           0.0                            4.762174   \n",
      "\n",
      "   geo_location  geo_location_country  geo_location_state   ad_id  \\\n",
      "0          2702                   216                2370  146617   \n",
      "1          2365                   216                2331  149696   \n",
      "2          2523                   216                2350  194361   \n",
      "\n",
      "   document_id  platform  document_id_promo  campaign_id  ...  \\\n",
      "0       414700         3              15618        20643  ...   \n",
      "1       417175         3              32816        14615  ...   \n",
      "2       412662         4              31658        24181  ...   \n",
      "\n",
      "   TE_campaign_id_clicked  TE_advertiser_id_clicked  TE_source_id_clicked  \\\n",
      "0                0.187568                  0.154453              0.266690   \n",
      "1                0.080187                  0.042270              0.209091   \n",
      "2                0.390006                  0.374190              0.178860   \n",
      "\n",
      "   TE_publisher_id_clicked  TE_source_id_promo_clicked  \\\n",
      "0                 0.276588                    0.154789   \n",
      "1                 0.213845                    0.046600   \n",
      "2                 0.171716                    0.372898   \n",
      "\n",
      "   TE_publisher_id_promo_clicked  clicked  \\\n",
      "0                       0.195423        0   \n",
      "1                       0.195423        0   \n",
      "2                       0.195343        0   \n",
      "\n",
      "   document_id_document_id_promo_sim_categories  \\\n",
      "0                                      0.974423   \n",
      "1                                      0.000000   \n",
      "2                                      0.000000   \n",
      "\n",
      "   document_id_document_id_promo_sim_topics  \\\n",
      "0                                       0.0   \n",
      "1                                       0.0   \n",
      "2                                       0.0   \n",
      "\n",
      "   document_id_document_id_promo_sim_entities  \n",
      "0                                         0.0  \n",
      "1                                         0.0  \n",
      "2                                         0.0  \n",
      "\n",
      "[3 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert output from triton back to a nvt dataframe  \n",
    "output = cudf.DataFrame({col: response.as_numpy(col).T[0] for col in workflow.column_group.columns})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_time_since_published</th>\n",
       "      <th>publish_time_promo_since_published</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>geo_location_country</th>\n",
       "      <th>geo_location_state</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>document_id_promo</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>...</th>\n",
       "      <th>TE_campaign_id_clicked</th>\n",
       "      <th>TE_advertiser_id_clicked</th>\n",
       "      <th>TE_source_id_clicked</th>\n",
       "      <th>TE_publisher_id_clicked</th>\n",
       "      <th>TE_source_id_promo_clicked</th>\n",
       "      <th>TE_publisher_id_promo_clicked</th>\n",
       "      <th>clicked</th>\n",
       "      <th>document_id_document_id_promo_sim_categories</th>\n",
       "      <th>document_id_document_id_promo_sim_topics</th>\n",
       "      <th>document_id_document_id_promo_sim_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>2702</td>\n",
       "      <td>216</td>\n",
       "      <td>2370</td>\n",
       "      <td>146617</td>\n",
       "      <td>414700</td>\n",
       "      <td>3</td>\n",
       "      <td>15618</td>\n",
       "      <td>20643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187568</td>\n",
       "      <td>0.154453</td>\n",
       "      <td>0.266690</td>\n",
       "      <td>0.276588</td>\n",
       "      <td>0.154789</td>\n",
       "      <td>0.195423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.564520</td>\n",
       "      <td>2365</td>\n",
       "      <td>216</td>\n",
       "      <td>2331</td>\n",
       "      <td>149696</td>\n",
       "      <td>417175</td>\n",
       "      <td>3</td>\n",
       "      <td>32816</td>\n",
       "      <td>14615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080187</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.213845</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.195423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>2523</td>\n",
       "      <td>216</td>\n",
       "      <td>2350</td>\n",
       "      <td>194361</td>\n",
       "      <td>412662</td>\n",
       "      <td>4</td>\n",
       "      <td>31658</td>\n",
       "      <td>24181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390006</td>\n",
       "      <td>0.374190</td>\n",
       "      <td>0.178860</td>\n",
       "      <td>0.171716</td>\n",
       "      <td>0.372898</td>\n",
       "      <td>0.195343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_time_since_published  publish_time_promo_since_published  \\\n",
       "0                           0.0                            4.564348   \n",
       "1                           0.0                            5.564520   \n",
       "2                           0.0                            4.762174   \n",
       "\n",
       "   geo_location  geo_location_country  geo_location_state   ad_id  \\\n",
       "0          2702                   216                2370  146617   \n",
       "1          2365                   216                2331  149696   \n",
       "2          2523                   216                2350  194361   \n",
       "\n",
       "   document_id  platform  document_id_promo  campaign_id  ...  \\\n",
       "0       414700         3              15618        20643  ...   \n",
       "1       417175         3              32816        14615  ...   \n",
       "2       412662         4              31658        24181  ...   \n",
       "\n",
       "   TE_campaign_id_clicked  TE_advertiser_id_clicked  TE_source_id_clicked  \\\n",
       "0                0.187568                  0.154453              0.266690   \n",
       "1                0.080187                  0.042270              0.209091   \n",
       "2                0.390006                  0.374190              0.178860   \n",
       "\n",
       "   TE_publisher_id_clicked  TE_source_id_promo_clicked  \\\n",
       "0                 0.276588                    0.154789   \n",
       "1                 0.213845                    0.046600   \n",
       "2                 0.171716                    0.372898   \n",
       "\n",
       "   TE_publisher_id_promo_clicked  clicked  \\\n",
       "0                       0.195423        0   \n",
       "1                       0.195423        0   \n",
       "2                       0.195343        0   \n",
       "\n",
       "   document_id_document_id_promo_sim_categories  \\\n",
       "0                                      0.974423   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "\n",
       "   document_id_document_id_promo_sim_topics  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "\n",
       "   document_id_document_id_promo_sim_entities  \n",
       "0                                         0.0  \n",
       "1                                         0.0  \n",
       "2                                         0.0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
